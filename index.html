<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Yehui Tang's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Yehui Tang is currently a senior researcher at Huawei Noah's Ark Lab.">
  <meta name="keywords" content="Yehui Tang, 唐业辉, tangyehui, Yehui, Tang, Deep Learning, Neural Architecture, LLM, PKU, Huawei">
  <meta name="author" content="Yehui Tang" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.jpg">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {

      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();

        // Store hash
        var hash = this.hash;

        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){

          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>YEHUI</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#projects" class="w3-bar-item w3-button">Projects</a>
    <a href="#publications" class="w3-bar-item w3-button">Publications</a>
    <a href="#service" class="w3-bar-item w3-button">Services</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">YEHUI</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 200px" alt="profile photo" src="images/yehui.png">
      <h1>Yehui Tang (唐业辉)</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">     
          I am a senior researcher at <a href="http://dev3.noahlab.com.hk/research.html">Huawei Noah's Ark Lab</a> working with <a href="https://www.wangyunhe.site">Yunhe Wang</a>. Before that, I obtained PhD from <a href="https://sai.pku.edu.cn/"> school of artifical intelligence</a> in Peking University, supervised by <a href="https://scholar.google.com/citations?hl=en&user=3J8OquAAAAAJ"> Prof. Chao Xu</a>. During my PhD, I study neural architecture design and model compression. Currently, I focus on developing powerful large language models, which feature a parameter scale from billions to trillions.         
        </p>
        <p class="w3-center">
          <a href="mailto:yehui.tang@huawei.com">yehui.tang@huawei.com</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=TkSZQ6gAAAAJ&hl=zh-CN">Google Scholar</a>
        </p>
        </tbody></table>
  </div>


<!-- The state Section -->
  <div class="w3-container w3-padding-32" id="state"> 
	<p><strong>Recruitment</strong>:  I am seeking highly self-motivated employees and interns who possess excellent coding skills and have a profound interest in Large Language Models. Please feel free to send me your resume!</p>
 </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
  	<h2>News</h2>
  	  <p><li> 04/2025, Serve as Area Chair for NeurIPS 2025.
  	  <p><li> 02/2024, We release the technical report of Pangu-Pi Pro, a tiny language model (1.5B) which can be easily implemented on edge devices. [<a style="color: #447ec9" href="https://arxiv.org/pdf/2402.02791">technical report</a>]
      </li></p> 
      <p><li> 12/2023, We release Pangu-Pi, a new architecture of LLM. [<a style="color: #447ec9" href="https://arxiv.org/pdf/2312.17276">technical report</a>]
      </li></p> 
      <p><li> 03/2022, 5 papers are accepted by CVPR 2022.</li></p>
 </div>


<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>

	<h4><strong>Pangu Ultra (135B): Pushing the Limits of Dense Large Language Models on Ascend NPUs</strong></h4>
        <img style="width:75%;" src="images/pangu-ultra.PNG"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://arxiv.org/pdf/2504.07866">Technical Report</a> | <a style="color: #447ec9" href="https://mp.weixin.qq.com/s/jzzW96NCBlCl6dtKMh0FTA">Synced
机器之心</a> 
        </p>
        <p class="w3-justify">
		<p><li>A 135B dense LLM trained on 8192 Ascend NPUs.
		<p><li>Competitive performance with DeepSeek-R1, whose sparse
model structure contains much more parameters.
        </p> 


	<h4><strong>PanGU-π Pro: Powerful Tiny Language Models (1B、1.5B、3B) for Edge Devices</strong></h4>
        <img style="width:65%;" src="images/pangu-pi-pro.PNG"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://arxiv.org/pdf/2402.02791">Technical Report</a> | <a style="color: #447ec9" href="https://mp.weixin.qq.com/s/0CysMLnaC-OfUqGFJk9qqw">Synced
机器之心</a> 
        </p>
        <p class="w3-justify">
        We introducing PanGu-π Pro, powerful tiny language model (1B, 1.5B, 3B) which can be easily implementd on edge devices. By an empirical investigation, we propose four strategies to improve performance:
		<p><li>Compact Tokenizer: efficient coverage of corpus.
		<p><li>Architecture Tweak: better depth and width tradeoffs.
		<p><li>Parameter Inheritance: powerful knowledge from larger LLMs.
		<p><li>Multiple-Round Training: memory reinforcement of tiny models.
        </p> 
 </div>



 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32" id="publications">
    <h2>Selected Publications</h2>
    The complete list of articles can be found on <a style="color: #447ec9" href="https://scholar.google.com/citations?user=TkSZQ6gAAAAJ&hl=zh-CN">Google Scholar</a>. 

    <p>
    <li><strong>Mixture of Lookup Experts.</strong>
    <br>
    Shibo Jie, <strong>Yehui Tang#</strong>, Kai Han, Yitong Li, Duyu Tang, Zhi-Hong Deng#, Yunhe Wang#
    <br>
    <a style="color: #447ec9" href="https://arxiv.org/pdf/2503.15798">paper</a> | <a style="color: #447ec9" href="https://github.com/JieShibo/MoLE">code</a>
    </p>

    <p>
    <li><strong>Forest-of-thought: Scaling test-time compute for enhancing LLM reasoning.</strong>
    <br>
    Zhenni Bi, Kai Han, Chuanjian Liu, <strong>Yehui Tang#</strong>, Yunhe Wang#
    <br>
    <a style="color: #447ec9" href="https://arxiv.org/pdf/2412.09078">paper</a> | <a style="color: #447ec9" href="https://github.com/iamhankai/Forest-of-Thought">code</a>
    </p>

       <p>
    <li><strong>MemoryFormer: Minimize Transformer Computation by Removing Fully-Connected Layers.</strong>
    <br>
    Ning Ding*, <strong>Yehui Tang*</strong>, Haochen Qin, Zhenli Zhou, Chao Xu, Lin Li, Kai Han, Liao Heng, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2024 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper_files/paper/2024/file/24143e25a82f856aeed58b2f497d623b-Paper-Conference.pdf">paper</a>
    </p>

    <p>
    <li><strong>PanGU-π Pro: Rethinking Optimization and Architecture for Tiny Language Models</strong>
    <br>
    <strong>Yehui Tang</strong>, Kai Han, Fangcheng Liu, Yunsheng Ni, Yuchuan Tian, Zheyuan Bai, Yi-Qi Hu, Sichao Li, Shangling Jui,  Yunhe Wang
    <br>
    <a style="color: #447ec9" href="https://arxiv.org/pdf/2402.02791">paper</a>
    </p>   

    <p>
    <li><strong>PanGU-π: Enhancing Language Model Architectures via Nonlinearity Compensation</strong>
    <br>
    Yunhe Wang, Hanting Chen, <strong>Yehui Tang</strong>, Tianyu Guo, Kai Han, Ying Nie, Xutao Wang, Hailin Hu, Zheyuan Bai, Yun Wang, Fangcheng Liu, Zhicheng Liu, Jianyuan Guo, Sinan Zeng, Yinchen Zhang, Qinghua Xu, Qun Liu, Jun Yao, Chao Xu, Dacheng Tao
    <br>
    <a style="color: #447ec9" href="https://arxiv.org/pdf/2312.17276">paper</a>
    </p>   


    <p>
    <li><strong>One-for-All: Bridge the Gap Between Heterogeneous Architectures in Knowledge Distillation</strong>
    <br>
    Zhiwei Hao, Jianyuan Guo, Kai Han, <strong>Yehui Tang</strong>, Han Hu, Yunhe Wang, Chang Xu
    <br>
    <em>NeurIPS</em> 2023 <strong>Highlight</strong> | <a style="color: #447ec9" href="https://openreview.net/pdf?id=8qePPvL1VY">paper</a>
    </p>   


    <p>
    <li><strong>Masked Image Modeling with Local Multi-Scale Reconstruction</strong>
    <br>
    Haoqing Wang, <strong>Yehui Tang</strong>, Yunhe Wang, Jianyuan Guo, Zhi-Hong Deng, Kai Han
    <br>
    <em>CVPR</em> 2023 <strong>Highlight</strong> | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Masked_Image_Modeling_With_Local_Multi-Scale_Reconstruction_CVPR_2023_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-Computing/tree/master/Self-supervised/LocalMIM">code</a>
    </p>    

    <p>
    <li><strong>Network Expansion for Practical Training Acceleration</strong>
    <br>
    Ning Ding, <strong>Yehui Tang</strong>, Kai Han, Chao Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2023 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Network_Expansion_for_Practical_Training_Acceleration_CVPR_2023_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-Computing/tree/master/TrainingAcceleration">code</a>
    </p>    

    <p>
    <li><strong>GhostNetV2: Enhance Cheap Operation with Long-Range Attention.</strong>
    <br>
    <strong>Yehui Tang</strong>, Kai Han, Jianyuan Guo, Chang Xu, Chao Xu, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2022 <strong>Spotlight</strong> | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/40b60852a4abdaa696b5a1a78da34635-Paper-Conference.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/ghostnetv2_pytorch">code</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/ghostnetv2">MindSpore code</a>
    </p>


    <p>
    <li><strong>An Image Patch is a Wave: Quantum Inspired Vision MLP (WaveMLP).</strong>
    <br>
    <strong>Yehui Tang</strong>, Kai Han, Jianyuan Guo, Chang Xu, Yanxi Li, Chao Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2022  <strong>Oral</strong> | <a style="color: #447ec9" href="https://arxiv.org/abs/2111.12294">paper</a> 
    </p>

    <p>
    <li><strong>Patch Slimming for Efficient Vision Transformers.</strong>
    <br>
    <strong>Yehui Tang</strong>, Kai Han, Yunhe Wang, Chang Xu, Jianyuan Guo, Chao Xu, Dacheng Tao 
    <br>
    <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/abs/2106.02852">paper</a> 
    </p>

    <p>
    <li><strong>Hire-MLP: Vision MLP via Hierarchical Rearrangement.</strong>
    <br>
    Jianyuan Guo*, <strong>Yehui Tang*</strong>, Kai Han, Xinghao Chen, Han Wu, Chao Xu, Chang Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2022 (* equal contribution) | <a style="color: #447ec9" href="https://arxiv.org/abs/2108.13341">paper</a> 
    </p>

    <p>
    <li><strong>CMT: Convolutional Neural Networks Meet Vision Transformers.</strong>
    <br>
    Jianyuan Guo, Kai Han, Han Wu, Chang Xu, <strong>Yehui Tang</strong>, Chunjing Xu, Yunhe Wang
    <br>
    <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://arxiv.org/abs/2107.06263">paper</a> 
    </p>


    <p>
    <li><strong>Source-Free Domain Adaptation via Distribution Estimation</strong>
    <br>
    Ning Ding, Yixing Xu, <strong>Yehui Tang</strong>, Chao Xu, Yunhe Wang, Dacheng Tao
    <br>
    <em>CVPR</em> 2022 
    </p>
    
    <p>
    <li><strong>Augmented Shortcuts for Vision Transformers</strong>
    <br>
    <strong>Yehui Tang</strong>,  Kai Han, Chang Xu, An Xiao, Yiping Deng, Chao Xu, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2021 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2021/file/818f4654ed39a1c147d1e51a00ffb4cb-Paper.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/augvit">MindSpore code</a>
    </p>
    
    <p>
    <li><strong>Manifold Regularized Dynamic Network Pruning</strong>
    <br>
    <strong>Yehui Tang</strong>, Yunhe Wang, Yixing Xu, Yiping Deng, Chao Xu, Dacheng Tao, Chang Xu
    <br>
    <em>CVPR</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2103.05861.pdf">paper</a> |
    <a style="color: #447ec9" href="https://github.com/yehuitang/Pruning/tree/master/ManiDP">code</a> |
    <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/ManiDP">MindSpore code</a>
    </p>
    
    <p>
    <li><strong>SCOP: Scientific Control for Reliable Neural Network Pruning</strong>
    <br>
    <strong>Yehui Tang</strong>, Yunhe Wang, Yixing Xu, Dacheng Tao, Chunjing Xu, Chao Xu, Chang Xu
    <br>
    <em>NeurIPS</em> 2020 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2010.10732">paper</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub/details?2593/noah-cvlab/gpu/1.0/resnet-0.65x_v1.0_oxford_pets">code</a>
    </p>
    
    <p>
    <li><strong>A Semi-Supervised Assessor of Neural Architectures</strong>
    <br>
    <strong>Yehui Tang</strong>, Yunhe Wang, Yixing Xu, Hanting Chen, Boxin Shi, Chao Xu, Chunjing Xu, Qi Tian, Chang Xu
    <br>
    <em>CVPR</em> 2020 | <a style="color: #447ec9" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Tang_A_Semi-Supervised_Assessor_of_Neural_Architectures_CVPR_2020_paper.pdf">paper</a>
    </p>
    
    <p>
    <li><strong>Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks</strong>
    <br>
    <strong>Yehui Tang</strong>, Yunhe Wang, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
    <br>
    <em>AAAI</em> 2020 | <a style="color: #447ec9" href="data/2020 AAAI dropblock.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/disout">code</a>
    </p>

    <p>
    <li><strong>Reborn filters: Pruning convolutional neural networks with limited data</strong>
    <br>
    <strong>Yehui Tang</strong>, Shan You, Chang Xu, Jin Han, Chen Qian, Boxin Shi, Chao Xu, Changshui Zhang
    <br>
    <em>AAAI</em> 2020 | <a style="color: #447ec9" href="https://ojs.aaai.org/index.php/AAAI/article/view/6058/5914">paper</a>
    </p>
    
    <p>
    <li><strong>Homogeneous Architecture Augmentation for Neural Predictor</strong>
    <br>
    Yuqiao Liu*, <strong>Yehui Tang*</strong>, Yanan Sun
    <br>
    <em>ICCV</em> 2021 (* equal contribution) | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Homogeneous_Architecture_Augmentation_for_Neural_Predictor_ICCV_2021_paper.pdf">paper</a>
    </p>
    
    
    <p>
    <li><strong>Learning frequency domain approximation for binary neural networks</strong>
    <br>
    Yixing Xu, Kai Han, Chang Xu, <strong>Yehui Tang</strong>, Chunjing Xu, Yunhe Wang
    <br>
    <em>NeurIPS</em> 2021 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2103.00841.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/FDA-BNN">MindSpore code</a>
    </p>
    
    <p>
    <li><strong>ReNAS: Relativistic Evaluation of Neural Architecture Search</strong>
    <br>
    Yixing Xu, Yunhe Wang, Kai Han, <strong>Yehui Tang</strong>, Shangling Jui, Chunjing Xu, Chang Xu
    <br>
    <em>CVPR</em> 2021 <strong>Oral</strong> | <a style="color: #447ec9" href="https://arxiv.org/pdf/1910.01523.pdf">paper</a>  | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub/details?noah-cvlab/gpu/1.1/renas_v1.0_cifar10">MindSpore code</a>
    </p>  <!-- <span style="color:red"> Oral Presentation</span>-->
    <p>
    <li><strong>Neuromorphic Camera Guided High Dynamic Range Imaging</strong>
    <br>
    Jin Han, Chu Zhou, Peiqi Duan, <strong>Yehui Tang</strong>, Chang Xu, Chao Xu, Tiejun Huang, Boxin Shi
    <br>
    <em>CVPR</em> 2020 | <a style="color: #447ec9" href="https://ojs.aaai.org/index.php/AAAI/article/view/6058/5914">paper</a>
    </p>

    <p>
    <li><strong>Frequency Domain Compact 3D Convolutional Neural Networks</strong>
    <br>
    Hanting Chen, Yunhe Wang, Han Shu, <strong>Yehui Tang</strong>, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu
    <br>
    <em>CVPR</em> 2020 | <a style="color: #447ec9" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Frequency_Domain_Compact_3D_Convolutional_Neural_Networks_CVPR_2020_paper.pdf">paper</a>
    </p>
    </ol>
    </p>

  <p>
    <li><strong>A Survey on Vision Transformer</strong>
    <br>
    Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu, <strong>Yehui Tang</strong>, An Xiao, Chunjing Xu, Yixing Xu, Zhaohui Yang, Yiman Zhang, Dacheng Tao
    <br>
    <em>IEEE T-PAMI</em> 2022 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/document/9716741">paper</a>
    </p>
    </ol>
  </p>

  </div>

<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Area chair of NeurIPS 2025. </p>
      <p><li> Senior program committee members of IJCAI 2021.</p>  <!--<a href="https://ijcai-21.org/">IJCAI 2021</a>-->
      <p><li> Program committee members of top-tie conferences like NeurIPS, ICML, ICLR, CVPR, ICCV, AAAI, etc.</p>
      <p><li> Journal Reviewers of IEEE T-PAMI, IEEE T-NNLS, Pattern Recognition, Neurocomputing, etc.</p> <!-- <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>-->
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2020, President's PhD Scholarship, Peking University.</p>
    <p><li> 2020, National Scholarship (top 1%), Chinese Ministry of Education.</p>
    <p><li> 2020, Pacemaker to Merit Student (top 1%), Peking University.</p>
    <p><li> 2016, National Scholarship (top 1%), Chinese Ministry of Education.</p>
    <p><li> 2015, National Scholarship (top 1%), Chinese Ministry of Education.</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">
    This website is based on the source code shared by <a href="https://www.wangyunhe.site">Dr. Yunhe Wang</a>. Thanks. 

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
